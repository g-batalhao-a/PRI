{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries\n",
    "\n",
    "- \"Apple pie\"\n",
    "- \"Chicken\" in the African category\n",
    "- \"Easy bread\" less than 2h\n",
    "- \"Pasta bolognese\"\n",
    "- \"Oatmeal\"\n",
    "\n",
    "Prioritize doing 3 of the queries first and running test models, then add more if possible.\n",
    "\n",
    "# Scoring\n",
    "\n",
    "Human classification of top 100 results obtained using the standard system (LTR-less). Scoring is done on a numeric scale from 0-5.\n",
    "\n",
    "## Criteria\n",
    "\n",
    "The attribution of a given score is a bit subjective but tries to follow the following guidelines:\n",
    "\n",
    "0. A document that does not match the query.\n",
    "1. A document that vaguely matches the query, is very incomplete (missing important fields, like instructions) and has no reviews. Or has very negative reviews.\n",
    "2. A document that partially matches the query, is incomplete and has no reviews. Or a document with negative reviews.\n",
    "3. A document that matches the query semantically, is reasonably complete (may miss more than two fields) and has at least one positive review.\n",
    "4. A document that perfectly or almost perfectly matches the query semantically, is complete or missing just one of the fields and has a good number of positive reviews (5 to 20).\n",
    "5. A document that perfectly matches the query semantically, is complete (the recipe has a full ingredient list, steps and cook time/nutritional information) and has a lot of positive reviews (more than 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse as urlp\n",
    "\n",
    "URL = \"http://localhost:8983/solr/recipes/select\"\n",
    "URL += \"?rows=100\"\n",
    "URL += \"&q.op=AND\"\n",
    "URL += \"&q={q}\"\n",
    "URL += \"&qf=\" + \"Name^5 Description Ingredients^2 Keywords^2 Instructions Reviews^0.5 AuthorName^0.2\"\n",
    "URL += \"&wt=json\"\n",
    "URL += \"&defType=edismax\"\n",
    "URL += \"&fl=id,RecipeId,score,[features]\"\n",
    "URL += \"&rq={{!ltr model=myModel reRankDocs=100 efi.text={q}}}\"\n",
    "URL += \"&fq={fq}\"\n",
    "\n",
    "query = [\"apple pie\", \"chicken\", \"easy bread\", \"pasta bolognese\", \"oatmeal\"]\n",
    "facet = [\"\", \"Category_Facet:African\", \"\", \"\", \"\"]\n",
    "urls = [URL.format(q=query[i], fq=facet[i]) for i in range(len(query))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import simplejson\n",
    "import pandas as pd\n",
    "\n",
    "for (idx, url) in enumerate(urls):\n",
    "    response = requests.request(\"GET\", url)\n",
    "    json = simplejson.loads(response.text)\n",
    "\n",
    "    for doc in json[\"response\"][\"docs\"]:\n",
    "        doc[\"URL\"] = \"http://localhost:3000/recipe/{0}\".format(doc[\"RecipeId\"]) \n",
    "        doc[\"query\"] = query[idx]\n",
    "        doc[\"facet\"] = facet[idx]\n",
    "    \n",
    "    df = pd.DataFrame(json[\"response\"][\"docs\"])\n",
    "    df.to_csv(\"queries/query{0}_results.csv\".format(idx+1), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "Solr's LTR implementation supports two different kinds of models: Linear and Tree Based.\n",
    "\n",
    "There are various algorithms that may be used in order to create these models. We will demonstrate the use of two, one for each type:\n",
    "\n",
    "- A Linear Model using Support Vector Machines\n",
    "- A Neural Network model built using RankNet\n",
    "\n",
    "We will use SciKit Learn's SVM implementation and a RankNet implementation built into Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import simplejson\n",
    "import glob\n",
    "\n",
    "result_files = glob.glob(\"queries/*_results.csv\")\n",
    "scores_files = glob.glob(\"queries/*_scores.csv\")\n",
    "\n",
    "result_files.sort()\n",
    "scores_files.sort()\n",
    "\n",
    "inputs = pd.concat((pd.read_csv(file) for file in result_files), ignore_index=True)\n",
    "scores = pd.concat((pd.read_csv(file) for file in scores_files), ignore_index=True)\n",
    "\n",
    "X = []\n",
    "Y = [entry.score for entry in scores.itertuples()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(entry):\n",
    "    req_url = \"http://localhost:8983/solr/recipes/select?rows=100&q.op=AND&q={q}&qf=Name^5%20Description%20Ingredients^2%20Keywords^2%20Instructions%20Reviews^0.5%20AuthorName^0.2&wt=json&defType=edismax&fl=[features]&fq={fq}&rq={rq}\"\n",
    "    facet = entry.facet\n",
    "    if pd.isna(facet):\n",
    "        facet = \"\"\n",
    "    response = requests.request(\"GET\", req_url.format(q=entry.query, fq=f\"RecipeId:{entry.RecipeId} {facet}\", rq=f\"{{!ltr model=myModel efi.text='{entry.query}'}}\"))\n",
    "    json = simplejson.loads(response.text)\n",
    "    return [float(feature.split(\"=\")[1]) for feature in json[\"response\"][\"docs\"][0][\"[features]\"].split(\",\")]\n",
    "\n",
    "\n",
    "for entry in inputs.itertuples():\n",
    "    X.append(get_features(entry))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "(train_x,\n",
    " test_x,\n",
    " train_y,\n",
    " test_y) = train_test_split(X, Y, test_size=0.25, random_state=1, stratify=Y)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonio/.asdf/installs/python/anaconda3-2020.11/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02679156372444591"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "linearSVM = svm.LinearSVR()\n",
    "lienarReg = linear_model.LinearRegression()\n",
    "\n",
    "linearSVM.fit(train_x, train_y)\n",
    "lienarReg.fit(train_x, train_y)\n",
    "\n",
    "pred_svm = linearSVM.predict(test_x)\n",
    "pred_reg = lienarReg.predict(test_x)\n",
    "\n",
    "r2_score(test_y, pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_file.dat\", 'w') as file:\n",
    "    for i in range(len(result_files[:4])):\n",
    "        in_f = pd.read_csv(result_files[i])\n",
    "        s_f = pd.read_csv(scores_files[i])\n",
    "        feats = [\" \".join([f\"{idx+1}:{f}\" for idx, f in enumerate(get_features(entry))]) for entry in in_f.itertuples()]\n",
    "        r_ids = [entry.RecipeId for entry in in_f.itertuples()]\n",
    "        scores = [entry.score for entry in s_f.itertuples()]\n",
    "        file.writelines(f\"{s} qid:{i} {f} # {id}\\n\" for f, s, id in zip(feats, scores, r_ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, url) in enumerate(urls):\n",
    "    response = requests.request(\"GET\", url)\n",
    "    json = simplejson.loads(response.text)\n",
    "\n",
    "    scores = pd.read_csv(scores_files[i])\n",
    "\n",
    "    for doc in json[\"response\"][\"docs\"]:\n",
    "        doc[\"score\"] = scores.loc[scores[\"RecipeId\"] == doc[\"RecipeId\"]][\"score\"].values\n",
    "        if len(doc[\"score\"]) > 0:\n",
    "            doc[\"score\"] = doc[\"score\"][0]\n",
    "        else:\n",
    "            doc[\"score\"] = \"\"\n",
    "        \n",
    "    df = pd.DataFrame(json[\"response\"][\"docs\"])\n",
    "    df.to_csv(\"queries/query{0}_ltr.csv\".format(i+1), index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.365997314453125\n"
     ]
    }
   ],
   "source": [
    "def probability_satisfied(grade):\n",
    "    return (pow(2, grade) - 1) / 32\n",
    "\n",
    "def probability_not_satisfied(probs):\n",
    "    pns = 1\n",
    "    for p in probs:\n",
    "        pns = pns * (1 - p)\n",
    "    return pns\n",
    "\n",
    "def err(grades):\n",
    "    err = 0\n",
    "    probs = []\n",
    "\n",
    "    for i, grade in enumerate(grades):\n",
    "        k = i + 1\n",
    "        ps = probability_satisfied(grade)\n",
    "        pns = probability_not_satisfied(probs)\n",
    "        \n",
    "        err = err + (1 / k) * ps * pns\n",
    "\n",
    "        probs.append(ps)\n",
    "\n",
    "    return err\n",
    "\n",
    "print(err([3, 2, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== QUERY 1 ====\n",
      "Original: [4, 2, 3, 3, 2, 2, 2, 5, 3, 3]\n",
      "Original score: 0.5889976478421203\n",
      "Ltr: [3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 5.0, 3.0, 4.0, 3.0]\n",
      "Ltr score: 0.4573671677939562\n",
      "\n",
      "==== QUERY 2 ====\n",
      "Original: [4, 4, 2, 3, 3, 5, 4, 4, 4, 3]\n",
      "Original score: 0.6505818905264783\n",
      "Ltr: [4, 5, 4, 1, 0, 2, 2, 0, 0, 0]\n",
      "Ltr score: 0.728974315870021\n",
      "\n",
      "==== QUERY 3 ====\n",
      "Original: [2, 4, 5, 3, 1, 5, 4, 1, 4, 4]\n",
      "Original score: 0.46439245074792324\n",
      "Ltr: [3.0, 5.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0]\n",
      "Ltr score: 0.6035056150392544\n",
      "\n",
      "==== QUERY 4 ====\n",
      "Original: [3, 2, 2, 3, 2, 2, 2, 3, 3, 2]\n",
      "Original score: 0.3540176718566535\n",
      "Ltr: [3, 3, 2, 3, 3, 2, 3, 3, 3, 3]\n",
      "Ltr score: 0.4015300825310471\n",
      "\n",
      "==== QUERY 5 ====\n",
      "Original: [4, 2, 3, 3, 1, 4, 4, 3, 3, 4]\n",
      "Original score: 0.5895515194293901\n",
      "Ltr: [4.0, 5.0, 5.0, 3.0, 3.0, 5.0, 5.0, 4.0, 4.0, 4.0]\n",
      "Ltr score: 0.731533770100546\n",
      "\n",
      "Average Original ERR: 0.5295082360805131\n",
      "Average LTR ERR: 0.5845821902669649\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "ltr_files = glob.glob(\"queries/*_ltr.csv\")\n",
    "ltr_files.sort()\n",
    "\n",
    "og_err = []\n",
    "ltr_err = []\n",
    "\n",
    "for (i, ltr_file) in enumerate(ltr_files):\n",
    "    og_scores = [entry.score for entry in pd.read_csv(scores_files[i]).itertuples()][:10]\n",
    "    ltr_scores = [entry.score for entry in pd.read_csv(ltr_file).itertuples()][:10]\n",
    "    og_err.append(err(og_scores))\n",
    "    ltr_err.append(err(ltr_scores))\n",
    "    print(f\"==== QUERY {i+1} ====\")\n",
    "    print(f\"Original: {og_scores}\")\n",
    "    print(f\"Original score: {err(og_scores)}\")\n",
    "    print(f\"Ltr: {ltr_scores}\")\n",
    "    print(f\"Ltr score: {err(ltr_scores)}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Average Original ERR: {mean(og_err)}\")\n",
    "print(f\"Average LTR ERR: {mean(ltr_err)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Queries\n",
    "\n",
    "## TQ1: Pumpkin pie\n",
    "\n",
    "### Regular\n",
    "\n",
    "- http://localhost:3000/recipe/8451 - 3\n",
    "- http://localhost:3000/recipe/99678 - 4\n",
    "- http://localhost:3000/recipe/141358 - 3\n",
    "- http://localhost:3000/recipe/155999 - 2\n",
    "- http://localhost:3000/recipe/190375 - 2\n",
    "- http://localhost:3000/recipe/195917 - 2\n",
    "- http://localhost:3000/recipe/195979 - 2\n",
    "- http://localhost:3000/recipe/196600 - 2\n",
    "- http://localhost:3000/recipe/197120 - 3\n",
    "- http://localhost:3000/recipe/199458 - 2\n",
    "\n",
    "### Boosted\n",
    "\n",
    "- http://localhost:3000/recipe/99678 - 4\n",
    "- http://localhost:3000/recipe/8451 - 3\n",
    "- http://localhost:3000/recipe/45262 - 3\n",
    "- http://localhost:3000/recipe/197120 - 3\n",
    "- http://localhost:3000/recipe/394476 - 4\n",
    "- http://localhost:3000/recipe/21047 - 5\n",
    "- http://localhost:3000/recipe/14186 - 5\n",
    "- http://localhost:3000/recipe/13888 - 3\n",
    "- http://localhost:3000/recipe/342359 - 3\n",
    "- http://localhost:3000/recipe/3558 - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== QUERY pumpkin pie ====\n",
      "Original: [3, 4, 3, 2, 2, 2, 2, 2, 3, 2]\n",
      "Original score: 0.4614534571170964\n",
      "Ltr: [4, 3, 3, 3, 4, 5, 5, 3, 3, 5]\n",
      "Ltr score: 0.6209241473960555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "og_scores = [3,4,3,2,2,2,2,2,3,2]\n",
    "ltr_scores = [4,3,3,3,4,5,5,3,3,5]\n",
    "\n",
    "print(f\"==== QUERY pumpkin pie ====\")\n",
    "print(f\"Original: {og_scores}\")\n",
    "print(f\"Original score: {err(og_scores)}\")\n",
    "print(f\"Ltr: {ltr_scores}\")\n",
    "print(f\"Ltr score: {err(ltr_scores)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TQ2: Vegetable curry\n",
    "\n",
    "### Regular\n",
    "\n",
    "- http://localhost:3000/recipe/49821 - 4\n",
    "- http://localhost:3000/recipe/120637 - 2\n",
    "- http://localhost:3000/recipe/134115 - 3\n",
    "- http://localhost:3000/recipe/90061 - 3\n",
    "- http://localhost:3000/recipe/41642 - 4\n",
    "- http://localhost:3000/recipe/496890 - 3\n",
    "- http://localhost:3000/recipe/7801 - 4\n",
    "- http://localhost:3000/recipe/8316 - 2\n",
    "- http://localhost:3000/recipe/15279 - 3\n",
    "- http://localhost:3000/recipe/21098 - 1\n",
    "\n",
    "### Boosted\n",
    "\n",
    "- http://localhost:3000/recipe/41642 - 4\n",
    "- http://localhost:3000/recipe/282585 - 3\n",
    "- http://localhost:3000/recipe/90061 - 3\n",
    "- http://localhost:3000/recipe/309611 - 4\n",
    "- http://localhost:3000/recipe/70361 - 3\n",
    "- http://localhost:3000/recipe/192353 - 3\n",
    "- http://localhost:3000/recipe/305712 - 3\n",
    "- http://localhost:3000/recipe/132070 - 3\n",
    "- http://localhost:3000/recipe/15279 - 3\n",
    "- http://localhost:3000/recipe/49821 - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== QUERY vegetable curry ====\n",
      "Original: [4, 2, 3, 3, 4, 3, 4, 2, 3, 1]\n",
      "Original score: 0.593063969548653\n",
      "Ltr: [4, 3, 3, 4, 3, 3, 3, 3, 3, 4]\n",
      "Ltr score: 0.6170006259430124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "og_scores = [4,2,3,3,4,3,4,2,3,1]\n",
    "ltr_scores = [4,3,3,4,3,3,3,3,3,4]\n",
    "\n",
    "print(f\"==== QUERY vegetable curry ====\")\n",
    "print(f\"Original: {og_scores}\")\n",
    "print(f\"Original score: {err(og_scores)}\")\n",
    "print(f\"Ltr: {ltr_scores}\")\n",
    "print(f\"Ltr score: {err(ltr_scores)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TQ3: Mojito\n",
    "\n",
    "### Regular\n",
    "\n",
    "- http://localhost:3000/recipe/9452 - 4\n",
    "- http://localhost:3000/recipe/231513 - 4\n",
    "- http://localhost:3000/recipe/269483 - 5\n",
    "- http://localhost:3000/recipe/260760 - 2\n",
    "- http://localhost:3000/recipe/340514 - 2\n",
    "- http://localhost:3000/recipe/403427 - 1\n",
    "- http://localhost:3000/recipe/502066 - 2\n",
    "- http://localhost:3000/recipe/505828 - 2\n",
    "- http://localhost:3000/recipe/511090 - 1\n",
    "- http://localhost:3000/recipe/516940 - 2\n",
    "\n",
    "### Boosted\n",
    "\n",
    "- http://localhost:3000/recipe/269483 - 5\n",
    "- http://localhost:3000/recipe/231513 - 4\n",
    "- http://localhost:3000/recipe/250822 - 5\n",
    "- http://localhost:3000/recipe/121715 - 3\n",
    "- http://localhost:3000/recipe/260323 - 4\n",
    "- http://localhost:3000/recipe/369597 - 4\n",
    "- http://localhost:3000/recipe/95096 - 4\n",
    "- http://localhost:3000/recipe/429288 - 4\n",
    "- http://localhost:3000/recipe/157973 - 2\n",
    "- http://localhost:3000/recipe/166675 - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== QUERY mojito ====\n",
      "Original: [4, 4, 5, 2, 2, 1, 2, 2, 1, 2]\n",
      "Original score: 0.6850325299349714\n",
      "Ltr: [5, 4, 5, 3, 4, 4, 4, 4, 2, 5]\n",
      "Ltr score: 0.9815327230797998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "og_scores = [4,4,5,2,2,1,2,2,1,2]\n",
    "ltr_scores = [5,4,5,3,4,4,4,4,2,5]\n",
    "\n",
    "print(f\"==== QUERY mojito ====\")\n",
    "print(f\"Original: {og_scores}\")\n",
    "print(f\"Original score: {err(og_scores)}\")\n",
    "print(f\"Ltr: {ltr_scores}\")\n",
    "print(f\"Ltr score: {err(ltr_scores)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TQ4: Beef stew\n",
    "\n",
    "### Regular\n",
    "\n",
    "- http://localhost:3000/recipe/3276 - 3\n",
    "- http://localhost:3000/recipe/51706 - 2\n",
    "- http://localhost:3000/recipe/118967 - 2\n",
    "- http://localhost:3000/recipe/122353 - 3\n",
    "- http://localhost:3000/recipe/149655 - 4\n",
    "- http://localhost:3000/recipe/152245 - 1\n",
    "- http://localhost:3000/recipe/156956 - 2\n",
    "- http://localhost:3000/recipe/160501 - 2\n",
    "- http://localhost:3000/recipe/179344 - 2 \n",
    "- http://localhost:3000/recipe/190865 - 2\n",
    "\n",
    "### Boosted\n",
    "\n",
    "- http://localhost:3000/recipe/42730 - 5\n",
    "- http://localhost:3000/recipe/290875 - 3\n",
    "- http://localhost:3000/recipe/37242 - 5\n",
    "- http://localhost:3000/recipe/336537 - 3\n",
    "- http://localhost:3000/recipe/72839 - 4\n",
    "- http://localhost:3000/recipe/22341 - 3\n",
    "- http://localhost:3000/recipe/73799 - 3\n",
    "- http://localhost:3000/recipe/414009 - 3\n",
    "- http://localhost:3000/recipe/50334 - 5 \n",
    "- http://localhost:3000/recipe/11970 - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== QUERY beef stew ====\n",
      "Original: [3, 2, 2, 3, 4, 1, 2, 2, 2, 2]\n",
      "Original score: 0.3711691678707563\n",
      "Ltr: [5, 3, 5, 3, 4, 3, 3, 3, 5, 4]\n",
      "Ltr score: 0.9801903125328307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "og_scores = [3,2,2,3,4,1,2,2,2,2]\n",
    "ltr_scores = [5,3,5,3,4,3,3,3,5,4]\n",
    "\n",
    "print(f\"==== QUERY beef stew ====\")\n",
    "print(f\"Original: {og_scores}\")\n",
    "print(f\"Original score: {err(og_scores)}\")\n",
    "print(f\"Ltr: {ltr_scores}\")\n",
    "print(f\"Ltr score: {err(ltr_scores)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TQ5: Noodles\n",
    "\n",
    "### Regular\n",
    "\n",
    "- http://localhost:3000/recipe/76748 - 4\n",
    "- http://localhost:3000/recipe/337591 - 2\n",
    "- http://localhost:3000/recipe/342444 - 2\n",
    "- http://localhost:3000/recipe/106277 - 2\n",
    "- http://localhost:3000/recipe/260825 - 2\n",
    "- http://localhost:3000/recipe/355406 - 3\n",
    "- http://localhost:3000/recipe/9993 - 4\n",
    "- http://localhost:3000/recipe/10691 - 5\n",
    "- http://localhost:3000/recipe/14477 - 3\n",
    "- http://localhost:3000/recipe/15171 - 2\n",
    "\n",
    "### Boosted\n",
    "\n",
    "- http://localhost:3000/recipe/61712 - 5\n",
    "- http://localhost:3000/recipe/177905 - 3\n",
    "- http://localhost:3000/recipe/136223 - 4\n",
    "- http://localhost:3000/recipe/182599 - 3\n",
    "- http://localhost:3000/recipe/167899 - 5\n",
    "- http://localhost:3000/recipe/9993 - 4\n",
    "- http://localhost:3000/recipe/211583 - 3\n",
    "- http://localhost:3000/recipe/76748 - 4\n",
    "- http://localhost:3000/recipe/70091 - 4 \n",
    "- http://localhost:3000/recipe/27344 - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== QUERY noodles ====\n",
      "Original: [4, 2, 2, 2, 2, 3, 4, 5, 3, 2]\n",
      "Original score: 0.5763049125893394\n",
      "Ltr: [5, 3, 4, 3, 5, 4, 3, 4, 4, 4]\n",
      "Ltr score: 0.978698259898458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "og_scores = [4,2,2,2,2,3,4,5,3,2]\n",
    "ltr_scores = [5,3,4,3,5,4,3,4,4,4]\n",
    "\n",
    "print(f\"==== QUERY noodles ====\")\n",
    "print(f\"Original: {og_scores}\")\n",
    "print(f\"Original score: {err(og_scores)}\")\n",
    "print(f\"Ltr: {ltr_scores}\")\n",
    "print(f\"Ltr score: {err(ltr_scores)}\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a6c239678afad6960c456aefc8713a9d49e3f9a7a9bb744edb151330f0438dc"
  },
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
